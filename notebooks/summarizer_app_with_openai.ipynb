{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e256ac24",
   "metadata": {},
   "source": [
    "Notebook creator: [Nikolaos Tsopanidis](https://github.com/tSopermon)\n",
    "# Summarization App Creation Notebook\n",
    "Material aqcuired from [Chanin Nantasenamat](https://blog.streamlit.io/langchain-tutorial-3-build-a-text-summarization-app/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068cc24",
   "metadata": {},
   "source": [
    "## Text Summarization\n",
    "Text summarization uses natural language processing to condense long-form content into a shorter summary while retaining key points. \n",
    "\n",
    "There are two types:\n",
    " 1. **Extractive summarization**: Selects and combines key phrases or sentences from the original text without altering them.\n",
    " 2. **Abstractive summarization**: Understands the main ideas and generates a concise, paraphrased summary, requiring deeper comprehension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5fc622",
   "metadata": {},
   "source": [
    "## App overview\n",
    " 1. **Input text submission**: to be summarized into the Streamlit frontend.\n",
    " 2. **Text preprocessing**: text is splitted into smaller chunks, creating documents for each chunk. This will help LLM model to summarize faster.\n",
    " 3. **Summary display**: how the summary will be displayed in the app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981390b",
   "metadata": {},
   "source": [
    "## Development process\n",
    " * **Input** text will be splitted into chunks using the `CharacterTextSplitter()` function from LangChain framework and we will create documents for each chunk using `Document()` function.\n",
    " * The LLM model will generate an **Output** from the processed input, using the `load_summarize_chain()` function.\n",
    "\n",
    "Steps are displayed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea785bef",
   "metadata": {},
   "source": [
    "### **Step 1**: Setting up the code environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a1a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install streamlit langchain langchain-huggingface tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d54f3",
   "metadata": {},
   "source": [
    "### **Step 2**: Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ef452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa4db06",
   "metadata": {},
   "source": [
    "### **Step 3**: Building the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119f69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(txt, openai_api_key):\n",
    "    llm = OpenAI(\n",
    "        temperature=0,\n",
    "        openai_api_key= openai_api_key\n",
    "    )\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=200,\n",
    "        chunk_overlap=20,\n",
    "        length_function=len\n",
    "    )\n",
    "    texts = text_splitter.split_text(txt)\n",
    "    # Create multiple documents\n",
    "    docs = [Document(page_content=t) for t in texts]\n",
    "    # summarization chain\n",
    "    chain = load_summarize_chain(\n",
    "        llm=llm,\n",
    "        chain_type=\"map_reduce\"\n",
    "    )\n",
    "    return chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page title\n",
    "st.set_page_config(page_title=\"Text Submission with Hugging Face and LangChain\", page_icon=\":guardsman:\")\n",
    "st.title(\"Text Submission with Hugging Face and LangChain\")\n",
    "\n",
    "# Text input\n",
    "txt_input = st.text_area(\"Enter your text:\", height=200)\n",
    "\n",
    "# form to accept user input\n",
    "result = []\n",
    "with st.form('summarize_form', clear_on_submit=True):\n",
    "    openai_api_key = st.text_input('OpenAI API Key', type = 'password', disabled=not txt_input)\n",
    "    submitted = st.form_submit_button(\"Submit\")\n",
    "    if submitted and openai_api_key.startswith(\"sk-\"):\n",
    "        with st.spinner(\"Generating summary...\"):\n",
    "            # Call the function to generate response\n",
    "            response = generate_response(txt_input, openai_api_key)\n",
    "            result.append(response)\n",
    "            del openai_api_key\n",
    "# Display the result\n",
    "if len(result):\n",
    "    st.info(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6958c36",
   "metadata": {},
   "source": [
    "### To use, create an OpenAI key from this [link](https://platform.openai.com/api-keys) to insert it on the app"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Data)",
   "language": "python",
   "name": "data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
